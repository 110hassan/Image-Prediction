{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810},{"sourceId":1317101,"sourceType":"datasetVersion","datasetId":642388},{"sourceId":2258144,"sourceType":"datasetVersion","datasetId":1357907}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport os\nimport random\nimport matplotlib.pyplot as plt\nimport pickle\nimport pandas as pd\nimport tensorflow\nfrom tensorflow import keras\nimport glob\nimport shutil\nfrom PIL import Image\nimport pickle\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn import preprocessing\nfrom keras.applications.vgg19 import VGG19, preprocess_input\nfrom keras.applications import ResNet50\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom keras.applications.inception_v3 import decode_predictions\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.metrics import AUC","metadata":{"execution":{"iopub.status.busy":"2024-01-27T09:07:01.156696Z","iopub.execute_input":"2024-01-27T09:07:01.157484Z","iopub.status.idle":"2024-01-27T09:07:11.399831Z","shell.execute_reply.started":"2024-01-27T09:07:01.157444Z","shell.execute_reply":"2024-01-27T09:07:11.398925Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset_path = '/kaggle/input/covid19-radiography-dataset/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset/COVID'\nworking_path = '/kaggle/working/Covid'\n\n# Ensure the destination directory exists\nos.makedirs(working_path, exist_ok=True)\n\n# List all files in the dataset folder\nall_images = os.listdir(dataset_path)\n\n# Shuffle the list of images to select a random subset\nrandom.shuffle(all_images)\n\n# Select the first 500 images\nselected_images = all_images[:1000]\n\n# Copy the selected images to the working directory\nfor image in selected_images:\n    source_path = os.path.join(dataset_path, image)\n    img = cv2.imread(source_path)\n    \n    # Resize the image to 224x224\n    img = cv2.resize(img, (224, 224))\n    \n    # Save the resized image to the working directory\n    destination_path = os.path.join(working_path, image)\n    cv2.imwrite(destination_path, img)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T08:35:44.261058Z","iopub.execute_input":"2024-01-27T08:35:44.261857Z","iopub.status.idle":"2024-01-27T08:35:58.761258Z","shell.execute_reply.started":"2024-01-27T08:35:44.261820Z","shell.execute_reply":"2024-01-27T08:35:58.760229Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"csv_file_path = '/kaggle/input/nih-chest-x-ray-14-224x224-resized/Data_Entry_2017.csv'\nsource_images_path = '/kaggle/input/nih-chest-x-ray-14-224x224-resized/images-224/images-224'\ndestination_path = '/kaggle/working/'\n\n# Read the CSV file into a pandas DataFrame\ndf = pd.read_csv(csv_file_path)\n\n# Define the classes you want to extract and the number of samples per class\nclasses_to_extract = ['Atelectasis', 'Consolidation', 'Infiltration', 'Effusion', 'Pneumothorax']\nsamples_per_class = 1000\n\n# Create the destination folders for each class\nfor class_name in classes_to_extract:\n    os.makedirs(os.path.join(destination_path, class_name), exist_ok=True)\n\n# Initialize a counter for each class\nclass_counters = {class_name: 0 for class_name in classes_to_extract}\n\n# Loop through the rows of the DataFrame and copy the images to the destination folders\nfor index, row in df.iterrows():\n    image_label = row['Finding Labels']  # Adjust 'label' based on your CSV column name\n\n    # Check if the image belongs to one of the classes you want to extract\n    if image_label in classes_to_extract and class_counters[image_label] < samples_per_class:\n        image_filename = row['Image Index']  # Adjust 'filename' based on your CSV column name\n        source_image_path = os.path.join(source_images_path, image_filename)\n        destination_image_path = os.path.join(destination_path, image_label, image_filename)\n\n        # Copy the image to the destination folder\n        shutil.copyfile(source_image_path, destination_image_path)\n\n        # Update the counter for the class\n        class_counters[image_label] += 1\n\nprint(\"Extraction completed.\")","metadata":{"execution":{"iopub.status.busy":"2024-01-27T08:37:24.465973Z","iopub.execute_input":"2024-01-27T08:37:24.466304Z","iopub.status.idle":"2024-01-27T08:38:37.914683Z","shell.execute_reply.started":"2024-01-27T08:37:24.466280Z","shell.execute_reply":"2024-01-27T08:38:37.913740Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Extraction completed.\n","output_type":"stream"}]},{"cell_type":"code","source":"Directory = r\"/kaggle/working/\"\n#arranging the list based on the folders saved in Directory\nCategories = [\"Normal\",\"Covid\",\"Pneumonia\",\"Atelectasis\",\"Effusion\",\"Pneumothorax\",\"Consolidation\",\"Infiltration\"]","metadata":{"execution":{"iopub.status.busy":"2024-01-27T09:07:21.251396Z","iopub.execute_input":"2024-01-27T09:07:21.252619Z","iopub.status.idle":"2024-01-27T09:07:21.257039Z","shell.execute_reply.started":"2024-01-27T09:07:21.252581Z","shell.execute_reply":"2024-01-27T09:07:21.256060Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data = []\n\nfor category in Categories:\n    path = os.path.join(Directory, category)\n    label = Categories.index(category)\n    for img in os.listdir(path):\n        img_array = cv2.imread(os.path.join(path, img))\n        img_array = cv2.resize(img_array, (224, 224))  # Use the original size (224, 224)\n        data.append([img_array, label])","metadata":{"execution":{"iopub.status.busy":"2024-01-27T09:07:24.943686Z","iopub.execute_input":"2024-01-27T09:07:24.944383Z","iopub.status.idle":"2024-01-27T09:07:36.837392Z","shell.execute_reply.started":"2024-01-27T09:07:24.944349Z","shell.execute_reply":"2024-01-27T09:07:36.836162Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"random.shuffle(data)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T09:07:41.298115Z","iopub.execute_input":"2024-01-27T09:07:41.298494Z","iopub.status.idle":"2024-01-27T09:07:41.310614Z","shell.execute_reply.started":"2024-01-27T09:07:41.298464Z","shell.execute_reply":"2024-01-27T09:07:41.309650Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X = []\ny = []\n\nfor features, labels in data:\n    X.append(features)\n    y.append(labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T09:07:50.945037Z","iopub.execute_input":"2024-01-27T09:07:50.946005Z","iopub.status.idle":"2024-01-27T09:07:50.958559Z","shell.execute_reply.started":"2024-01-27T09:07:50.945965Z","shell.execute_reply":"2024-01-27T09:07:50.957115Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X = np.array(X)\ny = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T09:07:59.071892Z","iopub.execute_input":"2024-01-27T09:07:59.072298Z","iopub.status.idle":"2024-01-27T09:07:59.478045Z","shell.execute_reply.started":"2024-01-27T09:07:59.072265Z","shell.execute_reply":"2024-01-27T09:07:59.477206Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-27T09:02:04.018995Z","iopub.execute_input":"2024-01-27T09:02:04.019908Z","iopub.status.idle":"2024-01-27T09:02:04.026370Z","shell.execute_reply.started":"2024-01-27T09:02:04.019871Z","shell.execute_reply":"2024-01-27T09:02:04.025431Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(8000, 224, 224, 3)"},"metadata":{}}]},{"cell_type":"code","source":"X = X/255","metadata":{"execution":{"iopub.status.busy":"2024-01-27T09:08:04.953266Z","iopub.execute_input":"2024-01-27T09:08:04.954056Z","iopub.status.idle":"2024-01-27T09:08:07.998955Z","shell.execute_reply.started":"2024-01-27T09:08:04.954015Z","shell.execute_reply":"2024-01-27T09:08:07.997845Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-24T21:31:05.692569Z","iopub.execute_input":"2024-01-24T21:31:05.693370Z","iopub.status.idle":"2024-01-24T21:31:05.702528Z","shell.execute_reply.started":"2024-01-24T21:31:05.693333Z","shell.execute_reply":"2024-01-24T21:31:05.701290Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"array([[[0.16078431, 0.16078431, 0.16078431],\n        [0.10588235, 0.10588235, 0.10588235],\n        [0.05882353, 0.05882353, 0.05882353],\n        ...,\n        [0.43921569, 0.43921569, 0.43921569],\n        [0.43529412, 0.43529412, 0.43529412],\n        [0.42745098, 0.42745098, 0.42745098]],\n\n       [[0.09411765, 0.09411765, 0.09411765],\n        [0.03921569, 0.03921569, 0.03921569],\n        [0.00784314, 0.00784314, 0.00784314],\n        ...,\n        [0.36862745, 0.36862745, 0.36862745],\n        [0.40784314, 0.40784314, 0.40784314],\n        [0.43921569, 0.43921569, 0.43921569]],\n\n       [[0.07843137, 0.07843137, 0.07843137],\n        [0.02352941, 0.02352941, 0.02352941],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.27058824, 0.27058824, 0.27058824],\n        [0.34509804, 0.34509804, 0.34509804],\n        [0.43921569, 0.43921569, 0.43921569]],\n\n       ...,\n\n       [[0.55686275, 0.55686275, 0.55686275],\n        [0.56078431, 0.56078431, 0.56078431],\n        [0.56470588, 0.56470588, 0.56470588],\n        ...,\n        [0.50196078, 0.50196078, 0.50196078],\n        [0.56078431, 0.56078431, 0.56078431],\n        [0.56078431, 0.56078431, 0.56078431]],\n\n       [[0.56078431, 0.56078431, 0.56078431],\n        [0.56470588, 0.56470588, 0.56470588],\n        [0.56862745, 0.56862745, 0.56862745],\n        ...,\n        [0.50196078, 0.50196078, 0.50196078],\n        [0.56078431, 0.56078431, 0.56078431],\n        [0.56078431, 0.56078431, 0.56078431]],\n\n       [[0.56470588, 0.56470588, 0.56470588],\n        [0.56862745, 0.56862745, 0.56862745],\n        [0.57254902, 0.57254902, 0.57254902],\n        ...,\n        [0.50196078, 0.50196078, 0.50196078],\n        [0.55686275, 0.55686275, 0.55686275],\n        [0.56078431, 0.56078431, 0.56078431]]])"},"metadata":{}}]},{"cell_type":"code","source":"#Using Pretrained Model\nbase_model = VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3))","metadata":{"execution":{"iopub.status.busy":"2024-01-27T09:08:18.895956Z","iopub.execute_input":"2024-01-27T09:08:18.896681Z","iopub.status.idle":"2024-01-27T09:08:20.904817Z","shell.execute_reply.started":"2024-01-27T09:08:18.896644Z","shell.execute_reply":"2024-01-27T09:08:20.903953Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"len(base_model.layers)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T09:08:24.176197Z","iopub.execute_input":"2024-01-27T09:08:24.176968Z","iopub.status.idle":"2024-01-27T09:08:24.184010Z","shell.execute_reply.started":"2024-01-27T09:08:24.176930Z","shell.execute_reply":"2024-01-27T09:08:24.183029Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"22"},"metadata":{}}]},{"cell_type":"code","source":"#Fine Tuning\n#1) Freezing the model layers\nfor layer in base_model.layers[:23]:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2024-01-27T09:08:26.545002Z","iopub.execute_input":"2024-01-27T09:08:26.545410Z","iopub.status.idle":"2024-01-27T09:08:26.551386Z","shell.execute_reply.started":"2024-01-27T09:08:26.545380Z","shell.execute_reply":"2024-01-27T09:08:26.550268Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#2) adding custom layers on top\nx = Flatten()(base_model.output)\nx = Dense(512, activation='relu')(x)         #increase the neurons (from 60 it went 62.)\n#x = Dropout(0.5)(x)\n#x = Dropout(0.5)(x)\nx = Dense(256, activation='relu')(x)\noutput_layer = Dense(len(Categories), activation='softmax')(x)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T09:09:03.377199Z","iopub.execute_input":"2024-01-27T09:09:03.378204Z","iopub.status.idle":"2024-01-27T09:09:03.431320Z","shell.execute_reply.started":"2024-01-27T09:09:03.378165Z","shell.execute_reply":"2024-01-27T09:09:03.430487Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#3) creating the model\nfrom tensorflow.keras.models import Model\nmodel = Model(inputs=base_model.input, outputs=output_layer)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T09:09:06.742580Z","iopub.execute_input":"2024-01-27T09:09:06.743390Z","iopub.status.idle":"2024-01-27T09:09:06.754161Z","shell.execute_reply.started":"2024-01-27T09:09:06.743354Z","shell.execute_reply":"2024-01-27T09:09:06.753251Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-27T09:09:16.895837Z","iopub.execute_input":"2024-01-27T09:09:16.896643Z","iopub.status.idle":"2024-01-27T09:09:16.961747Z","shell.execute_reply.started":"2024-01-27T09:09:16.896610Z","shell.execute_reply":"2024-01-27T09:09:16.960782Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n                                                                 \n flatten (Flatten)           (None, 25088)             0         \n                                                                 \n dense (Dense)               (None, 512)               12845568  \n                                                                 \n dense_1 (Dense)             (None, 256)               131328    \n                                                                 \n dense_2 (Dense)             (None, 8)                 2056      \n                                                                 \n=================================================================\nTotal params: 33003336 (125.90 MB)\nTrainable params: 12978952 (49.51 MB)\nNon-trainable params: 20024384 (76.39 MB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-01-27T09:09:23.119477Z","iopub.execute_input":"2024-01-27T09:09:23.119877Z","iopub.status.idle":"2024-01-27T09:09:23.138959Z","shell.execute_reply.started":"2024-01-27T09:09:23.119843Z","shell.execute_reply":"2024-01-27T09:09:23.138208Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model.fit(X, y, batch_size=32,\n          epochs=5, validation_split=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T09:09:25.955382Z","iopub.execute_input":"2024-01-27T09:09:25.955790Z","iopub.status.idle":"2024-01-27T09:13:10.929753Z","shell.execute_reply.started":"2024-01-27T09:09:25.955752Z","shell.execute_reply":"2024-01-27T09:13:10.928411Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/5\n225/225 [==============================] - 49s 181ms/step - loss: 1.5475 - accuracy: 0.4621 - val_loss: 1.1470 - val_accuracy: 0.5425\nEpoch 2/5\n225/225 [==============================] - 41s 184ms/step - loss: 1.0655 - accuracy: 0.5807 - val_loss: 1.0529 - val_accuracy: 0.5788\nEpoch 3/5\n225/225 [==============================] - 41s 181ms/step - loss: 1.0036 - accuracy: 0.6017 - val_loss: 0.9890 - val_accuracy: 0.6025\nEpoch 4/5\n225/225 [==============================] - 41s 181ms/step - loss: 0.9196 - accuracy: 0.6376 - val_loss: 0.9617 - val_accuracy: 0.6225\nEpoch 5/5\n225/225 [==============================] - 41s 181ms/step - loss: 0.8606 - accuracy: 0.6621 - val_loss: 0.9361 - val_accuracy: 0.6363\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7b2f95f26c50>"},"metadata":{}}]},{"cell_type":"code","source":"pickle.dump(model,open(\"VGG19Model.h5\",\"wb\"))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = pickle.load(open(\"\",\"rb\"))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = cv2.imread(\"/kaggle/input/covid19-radiography-dataset/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset/Lung_Opacity/Lung_Opacity-1011.png\")\n\n# Resize the image\nimage = cv2.resize(image, (224, 224))\n\n# Convert the image to grayscale\n\n# Normalize pixel values to the range [0, 1]\nimage = image / 255.0\n\n# Expand dimensions to match the input shape expected by the model\nimage = np.expand_dims(image, axis=0)\n# Convert to numpy array (optional, as the previous line already returns a NumPy array)\nimage = np.array(image)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diseases = [\"Pneumothorax\",\"Normal\",\"Infiltration\",\"Effusion\",\"Atelectasis\",\"Covid\",\"Pneumonia\",\"Consolidation\"]\npredictions = model.predict(image)\n\n# Print the top 5 predictions for each sample in the test data\ntop3_indices = np.argsort(predictions[0])[::-1][:3]  # Get indices of top 5 predictions\ntop3_classes = [f\"Class {index + 1}\" for index in top3_indices]\ntop3_probs = predictions[0][top3_indices]\n\nhighest_prob_index = top3_indices[0]\nhighest_prob_disease = diseases[highest_prob_index]\n\nprint(f\"Given Image - Top 3 Predictions:\")\nfor i in range(3):\n    print(f\"{top3_classes[i]}: {top3_probs[i]:.4f}\")\nprint(\"\\n\")\nprint(f\"Disease Predicted: {highest_prob_disease}\")","metadata":{},"execution_count":null,"outputs":[]}]}